else
{
samplesize = length(input)
sdvals=sd(input)
}
return(sdvals/sqrt(samplesize))
}
errorbars = function(aboves, belows, x=1:length(aboves), col="black")
{
arrows(x, belows, x, aboves, code=3, angle=90, length=0.02, col=col)
}
errorbarcolors = function(aboves, belows)
{
colors = ifelse(belows>0 | aboves < 0, "red", "black")
colors
}
clearworkspace = function()
{
rm(list=ls(pos=.GlobalEnv), pos=.GlobalEnv)
}
lowtemp = c(1.07, 1.11, 1.12, 1, 1.15, 1.13, 0.92, 1.07, 0.98, 1.07, 1.18,
1.03, 1.2, 1, 1.11, 1.13, 1.21, 1.09, 0.96, 0.94, 1.09, 1.21,
1.14, 1.23, 1.02, 1.12, 1.03, 1.3, 1.2, 1.16, 1, 1.06, 1.11,
1.04, 1.04, 1.03, 1.14, 1.21, 1.04, 1.11, 1.07, 1.09, 1.1, 0.97
)
hightemp = c(1.1, 1.15, 1.04, 1.07, 1.02, 1, 0.99, 1.02, 1.02, 0.98, 1.1,
1.02, 0.98, 0.93, 1.12, 0.93, 0.99, 1, 1.04, 0.9, 0.93, 1.1,
1.17, 1.1, 0.95, 0.91, 0.96, 1.01, 1.04, 1.06, 1, 0.84, 1.09,
0.86, 1.1, 1.01, 1.12, 1.08, 1, 0.94, 0.88, 1.1, 1.05, 1.02)
thorax_length = append(lowtemp, hightemp, after=length(lowtemp))
high= rep_len("high", 44)
low= rep_len("low", 44)
treatment = append(low, high, after= length(low))
expt <- data.frame(thorax_length, treatment)
color.list <- c("red", "blue")
palette(color.list)
s3 = function()
{
oldpar = par(mfcol=c(2,1))
nsamples = 100
samplesize = 25
datasets = sim(nsamples, samplesize)
plot(datasets$xvals, datasets$yvals, col="grey", xlab="Datasets", ylab="Simulated Values")
col.means = colMeans(datasets$yvals)
col.sems = sem(datasets$yvals)
points(1:nsamples, col.means, pch="x")
col.lowers = col.means-2*col.sems
col.uppers = col.means+2*col.sems
colors = errorbarcolors(col.uppers, col.lowers)
errorbars(col.uppers, col.lowers, col=colors)
abline(h=0, col="red")
print(count(0, col.lowers, col.uppers)/nsamples)
hist(col.means, breaks=20, xlab="Means", main="Histogram of Dataset Means\n(should be approximately bell-curved)")
par(oldpar)
}
s4 = function()
{
nsim = 1000
samplesize = 50
wildtype.mean = 300
wildtype.sd = 25
wildtype = sim(nsim, samplesize, wildtype.mean, wildtype.sd)
wildtype.col.means = colMeans(wildtype$yvals)
mutant = rnorm(samplesize, mean=290, sd=wildtype.sd)
print(mean(mutant) < 300)
print(t.test(mutant, mu=300, alternative="less")$p.value)
print(count(wildtype.col.means, 0, mean(mutant))/nsim)
}
missingpats<-c(1,49,52,63,65,78,6,57)
##get data, removing select patients
getMrnaData<-function() as.matrix(read.table('http://files.edx.org/MITx/7.QBWx/7qbwx_mrnaData.tab',sep='\t',as.is=T,header=T,row.names=1,fill=T)[,-missingpats])
read.url <- function(url, ...){
tmpFile <- tempfile()
download.file(url, destfile = tmpFile, method = "curl")
url.data <- read.csv(tmpFile, ...)
return(url.data)
}
getPatientData<-function(){
tab=read.url("https://courses.edx.org/c4x/MITx/7.QBW_1x/asset/7qbwx_patientData.csv",sep=',',as.is=T,header=T,fill=T,row.names=1)[-missingpats,]
tab[,3]<-as.numeric(tab[,3])
return(tab)
}
##get variance or SD for all rows of matrix
getAllRowVariance<-function(x) apply(x,1,var)
getAllRowStd<-function(x) apply(x,1,sd)
##compute correlation or sd for all rows in matrix
matrixToVectorCor<-function(matrix,vec) apply(matrix,1,function(x) cor(x,vec))
matrixToVectorSqCor<-function(matrix,vec) apply(matrix,1,function(x) cor(x,vec)^2)
mrna.data = getMrnaData()
patient.data = getPatientData()
all.sds = apply(mrna.data,1,sd)
sorted.sds = sort(all.sds,decreasing=T)
sorted.order = order(all.sds,decreasing=T)
sorted.matrix=mrna.data[sorted.order,]
life.vector=rep(0,ncol(mrna.data))
life.vector[which(patient.data[,2]=='Alive')] = 1
cor(sorted.matrix, life.vector)
all.cors = apply(sorted.matrix,1, function(x) cor(x,life.vector)^2)
test <- sqrt(all.cors)
test
sum(!is.na(test))
sum(!is.na(test) > 0.4)
test <- !is.na(test)
test
test <- test[!is.na(test)]
test
test <- sqrt(all.cors)
thing <- test[!is.na(test)]
thing
sum(thing > 0.4)
rm(list = ls())
A_table = read.table("pbmcs.txt", header=TRUE, row.names =1, sep = "", dec = ".")
#convert the dataframe into a matrix
A_matrix = as.matrix(A_table)
#transform the data
A_log = log(A_matrix+1)
A_pc = prcomp(A_log, retx = T)
A_pc
# Principal components
length(A_pc$sdev)
# Percent variation explained
pr_var = (A_pc$sdev)^2
percent_varex = pr_var/sum(pr_var)*100
percent_varex[1838]
percent_varex[1]
# Visualizin
plot(A_pc$x[,1], A_pc$x[,2], pch="*")
library(Rtsne)
install.packages("Rtsne")
A_tsne <- Rtsne(A_pc$x[,1:50], pca=F)
install.packages("Rtsne")
library("Rtsne")
A_tsne <- Rtsne(A_pc$x[,1:50], pca=F)
?qbinom
dbinom(2, size = 5, prob = 0.15)
0.5^8
0.4*0.35
pbinom(1, size = 3, prob = 0.9)
pbinom(0, size = 3, prob = 0.9)
pbinom(2, size = 3, prob = 0.9, lower.tail = FALSE)
pbinom(1, size = 3, prob = 0.9, lower.tail = FALSE)
3*0.9^2*0.1+0.9^3
0.6-0.3*0.3
175+110
80/110
0.475*0.890
475*890/1000
0.4+0.33-0.4*0.33
(1-25/100000)^100
1000*0.3+10000*0.1
1000^2*0.3+10000^2*0.1-1300^2
sqrt(8610000)
1.1*12.6
72.4*1.1+2
0.2^4*0.8
1/0.8
3*10-15
9*9+16
sqrt(97)
x <- c(1, 3, 7, 10)
y <- c(4, 6, 12, 15)
model <- lm(y ~ x)
summary(model)
sqrt(0.9932)
2.6+1.267*3
rm(list = ls())
####
#### 2. Logistic Regression Example
library(rpart)
help("kyphosis")
##Simulate one data set for linear regression
#Define the intercept and slope
BETA0 <- 0.5
BETA1 <- 0.75
#sample size of 40
n <- 40
#Generate x i.e. 40 observations from a normal dist. w/mean=100, SD=15
X <- rnorm(n,100,15)
#Generate y, 1st attempt
y <- BETA0 + BETA1*X
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
##Simulate one data set for linear regression
#Define the intercept and slope
BETA0 <- 0.5
BETA1 <- 0.75
#sample size of 40
n <- 40
#Generate x i.e. 40 observations from a normal dist. w/mean=100, SD=15
X <- rnorm(n,100,15)
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,1)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,1)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#Generate y, 2nd attempt--Need a random component, i.e. a normally distributed error
y <- BETA0 + BETA1*X + rnorm(n,0,10)
summary(lm(y~X))
#How to generate y?
eta <- BETA0 + BETA1*X
probs <- plogis(eta)
y <- rep(0,n)
for (i in 1:n){
u <- runif(1,0,1)
if (probs[i] < u){
y[i] <- 0
} else {y[i] <- 1}
}
#Or, more quickly
y <- rbinom(n,1,probs)
# Model
model <- glm(y ~ x, family = "binomial")
# Model
model <- glm(y ~ X, family = "binomial")
summary(model)
pnorm(-1)
pnorm(-1,lower.tail = FALSE)
pnorm(-1.5,lower.tail = FALSE)
pnorm(-2.5,lower.tail = FALSE)
pnorm(-3,lower.tail = FALSE)-0.5
pnorm(20000, mean = 29858, sd = 5600)
pnorm(30000, mean = 29858, sd = 5600)-pnorm(20000, mean = 29858, sd = 5600)
pnorm(30000, mean = 29858, sd = 5600)
qnorm(0.95, mean = 29858, sd = 5600)
pt(-5, df = 59) * 2
pnorm(30000, mean = 29858, s = 5600) - pnorm(20000, mean = 29858, s = 5600)
(30000-29858)/5600
0.5101-0.0392
qnorm(0.99)
# BiocManager::install("tidyverse")
# BiocManager::install("fgsea")
# BiocManager::install("data.table")
# BiocManager::install("msigdbr")
# BiocManager::install("RColorBrewer")
# BiocManager::install("topconfects")
# BiocManager::install("BiocParallel")
# BiocManager::install("tmod")
# BiocManager::install("recount")
# BiocManager::install("dorothea")
library("edgeR")
install.packages("edgeR")
library(edgeR)
# BiocManager::install("tidyverse")
# BiocManager::install("fgsea")
# BiocManager::install("data.table")
# BiocManager::install("msigdbr")
# BiocManager::install("RColorBrewer")
# BiocManager::install("topconfects")
# BiocManager::install("BiocParallel")
# BiocManager::install("tmod")
# BiocManager::install("recount")
# BiocManager::install("dorothea")
library("edgeR")
BiocManager::install("edgeR")
library("edgeR")
install.packages("edgeR")
library("edgeR")
library("limma")
library("Glimma")
library("rhdf5")
library("readr")
library("rjson")
library("ggplot2")
library("tibble")
library("qusage")
library("tidyverse")
library("fgsea")
library("data.table")
library("msigdbr")
library("RColorBrewer")
library("topconfects")
library("BiocParallel")
library("tmod")
library("dorothea")
library("recount")
BiocManager::install("Glimma")
# Install and load the required packages
BiocManager::install("edgeR")
warnings
warnings()
?prop.test
prop.test(c(680, 775), n = c(1077, 840), conf.level = 0.99)
prop.test(c(680, 775), n = c(1077, 840), conf.level = 0.99, correct = FALSE)
prop.test(c(680, 775), n = c(1077, 840), conf.level = 0.99, correct = FALSE)
prop.test(c(28, 32), n = c(350, 500), conf.level = 0.9, correct = FALSE)
pt(2.615, df = 14, lower.tail = FALSE)
?dgeom
rgeom(10, prob = 1/2)
rgeom(10, prob = 1/2) + 1
c = rgeom(1000, prob = 1/2)
c
c <- c + 1
c
p = 2 / (2 + c)
p
mean(p)
c <- c + 1
c = rgeom(1000, prob = 1/2)
c <- c + 1
p = 2 / (2 + c)
mean(p)
c = rgeom(10000, prob = 1/2)
c <- c + 1
p = 2 / (2 + c)
mean(p)
c = rgeom(100000, prob = 1/2)
c <- c + 1
p = 2 / (2 + c)
mean(p)
c = rgeom(100000, prob = 1/2)
p = 1 / c
p
c = rgeom(100000, prob = 1/2)
c <- c + 1
1 / c
mean(p)
p <- 1 / c
mean(p)
mean(c)
c = rgeom(100000, prob = 1/2)
c <- c + 1
mean(c)
mean(1 / c)
c = rgeom(1000, prob = 1/2)
mean(c)
c <- c + 1
c
mean(c)
1 / mean(c)
c = rgeom(100000, prob = 1/2)
c <- c + 1
mean(c)
1 / mean(c)
c = rgeom(10000, prob = 1/2)
c <- c + 1
mean(c)
1 / mean(c)
3*12
dpois(3, lambda = 36)
dpois(x = 30, lambda = 36)
1 - dpois(x = 1, lambda = 4.5) - dpois(x = 0, lambda = 4.5)
ppois(x = 2, lambda = 4.5, lower.tail = FALSE)
ppois(q = 2, lambda = 4.5, lower.tail = FALSE)
ppois(q = 1, lambda = 4.5, lower.tail = FALSE)
sqrt(3* 4)
dbinom(32, size = 40, prob = 0.8)
dbinom(30, size = 40, prob = 0.8)
0.8*40*500
500*sqrt(0.8*0.2*40)
0.9*0.8+0.1*0.65
0.1*0.65/(1-0.785)
0.65*0.1/(0.65*0.1+0.9*0.8)
259.2/6
259.2/6+10*25
293.2*4
sqrt(10)
qnorm(1.25) - qnorm(-1.25)
pnorm(1.25) - pnorm(-1.25)
qt(0.025, df = 177)
pnorm(0, mean = -1100, sd = sqrt(415^2+250^2), lower.tail = FALSE)
pnorm(-0.54)
1-0.295
?f.test
?f test
??f.test
x <- c(11.1, 12.18, 13.59, 10.87, 11.92)
y <- c(10.79, 14.25, 8.56, 21.91, 9.17, 12.51)
var.test(x, y)
var.test(y, x)
qf(0.05, df1 = 5, df2 = 4, lower.tail = FALSE)
qf(0.05/2, df1 = 5, df2 = 4, lower.tail = FALSE)
t.test(x, y)
t.test(y, x)
rm(list = ls())
x <- c(105.03, 115.85, 129.88, 102.70, 113.20, 115.32, 121.08)
t.test(x, mean = 104)
mean(x)
pf(51.213, df1 = 2, df2 = 27, lower.tail = FALSE)
qf(0.05, df1 = 2, df2 = 50, lower.tail = FALSE)
qnorm(0.006)
qnorm(-1.42)
pnorm(-1.42)
qnorm(0.006)
-2.51*6/5+74
(70.988-70)/(6/sqrt(25))
pnorm(0.823, lower.tail = FALSE)
pnrom(0.823)
pnorm(0.823)
pnorm(0.82)
pnorm(0.82, lower.tail = FALSE)
qnorm(0.99)
qnorm(0.006)
pnorm(1.2, lower.tail = FALSE)
-1/sqrt(2)
0.5-0.2389
pnorm(2, mean = 2, sd = sqrt(3)) - pnorm(1, mean = 2, sd = sqrt(3))
0.2611*0.218
pnorm(1, mean = 2, sd = 2) - pnorm(-1, mean = 2, sd = 2)
1-0.242
qnorm(0.05)
10+1.645(4)
10+1.645*4
pnorm(1, lower.tail = FALSE)
qt(0.98, df = 18)
pnorm(0.003) - pnorm(-0.337)
pnorm(41, mean = 50, sd = 3)
0.8630 - pnorm(41, mean = 50, sd = 3)
0.8630 + pnorm(41, mean = 50, sd = 3)
qnorm(0.864)
50 + 3*1.098468
qnorm(0.10)
(2-0.85)/1.93
pnorm(0.596, lower.tail = FALSE)
?binomcsd
pbinom(109, size = 400, prob = 0.3, lower.tail = FALSE)
pnorm(-1.145, lower.tail = FALSE)
?t.test
?sample
sample.int(25, size = 10)
sample.int(25, size = 25)
pnorm(2) - pnorm(-3)
0.082^2
0.116^2
0.397^2
sqrt(0.082^2+0.116^2)
0.389^2+0.116^2
sqrt(0.164777)
0.389^2
0.397^2+0.414^2
sqrt(0.329005)
0-0.003/0.574
pnorm(-0.005, lower.tail = FALSE)
pnorm(-2.318, lower.tail = FALSE)
x <- c(4, 11, 8, 7, 5)
y <- c(70, 80, 40, 57, 43)
model <- lm(y ~ x)
summary(model)
z <- c(30, 44, 38, 36, 32)
model2 <- lm(y~ z)
summary(model2)
2.133/1.067
43.067-2.133/2*22
getwd()
rm(list = ls())
setwd("~/Desktop/BE M228/LLM-ECG-Domain-Adaptation/Scripts")
# Import libraries
library(readr)
library(dplyr)
# Read in dataset
df <- read_delim("..//Data/subject-info.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
# Preprocessing
# Remove extraneous columns
# df <- df[, 1:105]
# Check for columns with missing values
for (i in 1:ncol(df)){
if (any(is.na(df[,i]))){
num_missing <- sum(is.na(df[,i]))
message(paste("The column ", colnames(df)[i], "has ", num_missing, "missing values."))
}
}
# Groups of patient features
# R indexes at 1; shift down by 1 for Python
demographics <- seq(6, 28) # 6, 7, ... 28
radiographic <- c(49, 50)
echocardiographic <- seq(51, 60) # 51, 52, ..., 60
laboratory <- seq(29, 48) # 29, 30, ..., 48
ecg <- seq(63, 71) # 63, 64, ..., 71
holter <- seq(74, 92) # 74, 75, ..., 92
medications <- seq(93, 105) # 93, 94, ..., 105
# Limit study to patients with sinus rhythms
df_sinus <- df[df$`Holter  rhythm` == 0, ] # 710 patients
# Assign patients with exit of study as NA to values of 0 (assume survivor)
df_sinus$`Exit of the study`[is.na(df_sinus$`Exit of the study`)] <- 0
# Remove patients who were lost to follow-up or had cardiac transplantation
df_sinus <- df_sinus[df_sinus$`Exit of the study` == 0 | df_sinus$`Exit of the study` == 3,] # 694 patients
# Remove patients with non-cardiac deaths
df_sinus <- df_sinus[df_sinus$`Cause of death` != 1, ] # Down to 663 patients
# Reassign pump failure values to only be 7
df_sinus$`Cause of death`[df_sinus$`Cause of death` == 7] <- 6
# Get patients with Holter ECG
# df_sinus <- df_sinus %>% filter(df_sinus$`Hig-resolution ECG available` != 0)
df_sinus <- df_sinus %>% filter(df_sinus$`Holter available` != 0) # Results in 604 patients
# Sort by class
df_sinus <- df_sinus[order(df_sinus$`Cause of death`),]
# Number in each class
table(df_sinus$`Cause of death`)
# Print dataframe to csv file (to later be used in Python)
write.csv(df_sinus, file = "../Data/subject-info-cleaned.csv")
